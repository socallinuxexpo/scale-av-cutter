#!/usr/bin/env python3

import os
import sys
import json
import argparse
import re
from google_auth_oauthlib.flow import InstalledAppFlow
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

vformat = "mp4"

def rdash(s):
    return re.sub('[^0-9a-zA-Z]+', '-', s)

def obtain_credentials_from_flow(client_file):
    flow = InstalledAppFlow.from_client_secrets_file(
        client_file,
        scopes=['https://www.googleapis.com/auth/youtube'])
    flow.run_console()
    return flow.credentials

def obtain_credentials_from_token(token_file):
    return Credentials.from_authorized_user_file(
        token_file,
        scopes=['https://www.googleapis.com/auth/youtube'])

def make_video_description(talk):
    link = "https://www.socallinuxexpo.org" + talk["path"]
    return f"""\
Talk by {talk["speakers"]}

{link}

{talk["description"]}"""

def collect_talks(room_days, workdir):
    talks = []

    for room_day in room_days["room_days"]:
        room = room_day["room"]
        day = room_day["day"]

        room_day_name = f"{rdash(room)}-{rdash(day)}"
        subdir_path = os.path.join(workdir, room_day_name)

        for talk in room_day["talks"]:
            title = rdash(talk["title"])

            talk_name = f"{title}.{vformat}"
            talk_path = os.path.join(subdir_path, talk_name)
            if not os.path.isfile(talk_path):
                talk_path = None
            talks.append({
                "path": talk["path"],
                "title": talk["title"],
                "description": make_video_description(talk),
                "file": talk_path,
            })

    return talks

def parse_args():
    parser = argparse.ArgumentParser(description="Takes a JSON file generated by the scale-av-cutter, and finds and uploads the videos cut by split.py to the user's Youtube account. It is usually safe to run upload.py again, since progress is by default saved to a progress file. Already-uploaded talks will be skipped, but partially uploaded talks will have to restart from scratch.")

    parser.add_argument("json", help="Path to json file of cut details")
    parser.add_argument("-w", "--workdir", default="workdir", help="Working subdirectory to find cut videos in (default: %(default)s)")
    parser.add_argument("--skip-missing-talks", action="store_true", help="Continue to upload even if some talks specified in the json are missing in workdir")
    parser.add_argument("-c", "--client", default="client_secrets.json", help="Path to client secrets file. Required if token is not valid (default: %(default)s)")
    parser.add_argument("-t", "--token", default="credentials.json", help="Path to authorization token file. If does not exist or invalid, this script will take you through the Google OAuth process (default: %(default)s)")
    parser.add_argument("--no-save-token", dest="save_token", action="store_false", help="Disable saving the authorization token to the path specified in (--token), after authorization.")
    parser.add_argument("-p", "--progress", default="progress.json", help="Path to talk upload progress file. If does not exist, all talks will be reuploaded.")
    parser.add_argument("--no-save-progress", dest="save_progress", action="store_false", help="Disable saving the uploaded status of talks to the path specified in (--progress).")
    parser.add_argument("--privacy", default="unlisted", choices=["public", "private", "unlisted"], help="Set the privacy status of uploaded videos (default: %(default)s)")
    return parser.parse_args()

def main():
    args = parse_args()

    # Collect talks
    print(f"Parsing {args.json}")
    with open(args.json) as f:
        room_days = json.load(f)
    if os.path.isfile(args.progress):
        with open(args.progress) as f:
            progress = json.load(f)
    else:
        progress = {}
    talks = collect_talks(room_days, args.workdir)
    filtered_talks = []
    for talk in talks:
        if talk["file"] is None and not args.skip_missing_talks:
            sys.exit(f"ERROR: video for {talk['title']} not found.")
        elif talk["file"] is None and args.skip_missing_talks:
            print(f"WARNING: video for {talk['title']} not found. Skipping.")
            continue
        elif talk["path"] in progress:
            print(f"Already uploaded: {talk['title']}.")
            continue
        print(f"Found talk: {talk['title']}")
        filtered_talks.append(talk)
    talks = filtered_talks
    print(f"Total: {len(talks)} talks to upload")
    if not talks:
        return

    # Google API
    if os.path.isfile(args.token):
        print(f"Found {args.token}, reusing credentials")
        credentials = obtain_credentials_from_token(args.token)
    else:
        print(f"Cannot find token file at {args.token}, starting authentication process")
        credentials = obtain_credentials_from_flow(args.client)
    if args.save_token:
        with open(args.token, "w") as f:
            json.dump({
                "client_id": credentials.client_id,
                "client_secret": credentials.client_secret,
                "refresh_token": credentials.refresh_token,
            }, f)

    # Upload!
    yt = build('youtube', 'v3', credentials=credentials)
    for talk in talks:
        size = os.path.getsize(talk["file"])
        print(f"Uploading \"{talk['title']}\" ({size} bytes)...")
        video = MediaFileUpload(talk['file'])
        request = yt.videos().insert(
            part="id,snippet,status",
            body={
                "snippet": {
                    "title": talk["title"],
                    "description": talk["description"],
                },
                "status": {
                    "privacyStatus": args.privacy,
                },
            },
            media_body=video)
        response = request.execute()
        url = f"https://youtube.com/watch?v={response['id']}"
        print("Upload complete: " + url)
        if args.save_progress:
            progress[talk["path"]] = True
            with open(args.progress, "w") as f:
                json.dump(progress, f)

if __name__ == "__main__":
    main()
